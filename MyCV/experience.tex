% the mega teaching section
% \section{Honors and Awards}
% \cvline{2019}{\textbf{Novatek 2019 Scholarship}}
% \cvline{2019}{\textbf{Ministry of Science and Technology (Taiwan) Travel Grant}}
% \cvline{2018}{\textbf{Novatek 2018 Scholarship}}
% \cvline{2018}{\textbf{IEEE PerCom 2018 Best PhD Forum Presentation Award}}
% \cvline{2018}{\textbf{Principal Scholarship, NTHU}}
% \cvline{2017}{\textbf{APNOMS 2017 Student Travel Grant}}
% \cvline{2017}{\textbf{Principal Scholarship, NTHU}}
% \cvline{2016}{\textbf{Ministry of Science and Technology (Taiwan) Travel Grant}}
% \cvline{2016}{\textbf{ACM Multimedia 2016 Student Travel Grant}}
% \cvline{2016}{\textbf{Principal Scholarship, NTHU}}
% \cvline{2015}{\textbf{Pan Wen-Yuan Foundation Scholarship}}
% \cvline{2015}{\textbf{Ministry of Science and Technology (Taiwan) Travel Grant}}
% \cvline{2015}{\textbf{ACM Multimedia Systems 2015 Student Travel Grant}}
%\cvline{2011}{\textbf{National Tsing Hua University, Collegiate Programming Examination} {Qualified}}
%\cvline{2011}{\textbf{ACM-ICPC Asia HsinChu Regional Contest} {Honorable Mention}}



%\newpage
\section{Research Experience}
\cventry{}{6-DoF Immersive Video Streaming}{(Supported by the MOST Project: Teleporting Through Space Across Time Using Head-Mounted Displays: A Case Study for Real Estate)}{}{}
{Virtual Reality (VR) has become increasingly more popular in various business sectors. 
The modern VR systems that support
six-degree-of-freedom (6-DoF) can provide more immersive experience, in which Head-Mounted-Display (HMD) userâ€™s viewport can be changed
according to his/her position and orientation. However, because of the tremendous content size, 6-DoF immersive
video streaming dictates too much bandwidth and computing resources. In this work, we propose a configuration
optimizer that uses Reinforcement Learning (RL) and Convolutional Neural Network (CNN) to 
select the best configuration setting. Through real experiments, we show that our solution reduces the bandwidth and computing resource consumption while delivering
good video quality.
} \\
\cventry{}{Machine Learning Platform}{(Supported by the UMC Project: Development for AI Related Edge and Infrastructure)}{}{} 
{
Machine Learning (ML) has been around for decades
and is now commonly used in many fields. 
In recent years, more and more companies try to use ML techniques to achieve or improve their
productibility. However, capitalizing the potential of ML needs a lot of domain knowledge, along with tons of tuning for the best performance.
Furthermore, ML applications are not done after a model is trained. This is because the trained models may become outdated in the future, due to the drifts of concepts. 
Therefore, after deploying an ML model, we still need to monitor its performance and retrain it whenever necessary.
% These problems lead to a requirement of software to allow developers to do these repeat jobs automatically.
To allow the ML developers to focus on analysis, we need an ML platform that can automate the routine tasks.
In this project, we build such an ML platform, which consists of various tools to speed up data preparation, model building, service serving, and performance monitoring of multiple ML applications.
We survey the existing platforms and generalize their components and functions.
This leads to a general ML platform design that can be adopted in diverse scenarios.
To demonstrate the practicality and efficiency of our design, we build a real testbed based on several open-source projects like Kubeflow.
We use the testbed to conduct a case study, which results in a few new research problems, that were not solved in the literature. We are currently solving these problems jointly with the UMC colleagues. 
}\\
%\cventry{}{Video Streaming Over Crowded WiFi Network}{}{}{}
%{When doing video conferencing with a laptop in a conference room, we like to use IP camera mounted on ceiling rather than use the camera equipped by the laptop since the laptop camera has limited coverage and inferior quality compared to the IP camera. We also like to use the projector to project the video from another client to the screen to make sure all of users at this side can see another participants clearly. It may waste much time on setting the conference if all these devices (laptop, IP camera and projector) are connected others via cables. Therefore, we think that the more efficient solution is connecting all these devices via WiFi networks. However, the connection of so many IP devices may make the single access point be crowded with multiple video streams, which may lead to inferior user experience due to the congested networks. We plan to design and implement a system using IEEE 802.11e (QoS) mechanism, which is able to classify and prioritize each stream for resource (bandwidth) allocation, to handel the crowded WiFi streams. We also plan to measure the available bandwidth and take the background interference into consideration to improve the resource allocation and maximize the user experience.}\\
% \section{Research Projects}
% \cventry{}{360-degree Video Streaming to HMD Display}{}{}{}
% {
% Recently, 360-degree videos are getting popular, because they preserve
% immersive experience, allowing people to better share their life and 
% experience. However, streaming 360{\degree} videos to Head-Mounted Displays 
% (HMDs) is challenging due to large video sizes and complex human visual systems. We study three core problems to optimize the: (i) production, (ii) transmission, and (iii) consumption of 360{\degree} video content in the emerging streaming systems to HMDs. First, we develop a divide-and-conquer approach to optimize the encoding ladder of immersive tiled videos by considering the video models, viewing probabilities, and client distribution. Second, we design a neural network and leverage sensor and content features to predict the future viewport of immersive tiled videos. Last, we design and conduct user studies to construct a gaze-aware immersive Quality-of-Experience (QoE) model for quantifying the impacts of various QoE factors. 
%The outcomes of these three studies result in better optimized immersive video streaming systems to HMDs. Our developed technology and accumulated experience will be the cornerstone of the upcoming Virtual Reality (VR), Mixed Reality (MR), and Augmented Reality (AR), collectively referred to as Extended Reality (XR), applications.
% }\\
%{Recently, 360-degree videos are getting popular, because they preserve
%immersive experience, allowing people to better share their life 
%and experience. Leverage Head-Mounted Display (HMD) for 360-degree video
%streaming leads to several challenges. 360-degree is in extremely 
%high resolution, which may lead to inferior user experience due to high
%bandwidth requirements. However, each HMD viewer only get to see a small 
%part of the whole video. A better solution is to only stream the current 
%FoV of the viewer. Predicting future viewing probability allows a further
%optimization on tile rate selection, which reduces the network bandwidth 
%requirements while providing higher user experience. We build a 360-degree
%video streaming testbed to collect dataset and leverage neural networks 
%to predict user fixations on 360-degree videos. The collected dataset 
%is then used to train and validate our proposed fixation prediction 
%network. Besides, we have designed optimal laddering algorithm 
%using Lagrangian multiplier to improve the viewing quality at production
%phase. Moreover, we are deriving QoE model for watching
%360{\degree} videos in HMD to better reflect the user experience than
%existing objective quality metrics.} \\
%\newpage

% \section{Professional and Teaching Experiences}
% \cvline{June 2017}{Technical Program Committee Member, MMSys 2017 Dataset Track}
% \cvline{Spring 2016}{Teaching Assistant, Wireless Multimedia Networking Technologies and Applications, Department of Computer Science, NTHU}
% \cvline{September 2014 -- Present}{Research Assistant, Networking and Multimedia System Lab, Department of Computer Science, NTHU}

%\section{Selected Coursework}
%\cvline{}{Game Programming (A+), Cloud Programming (A-)}
%\cvline{}{Multimedia Coding (A), String Matching Algorithm (A+)}
%\cvline{}{Wireless Multimedia Networking Technologies and Applications (A)}
%\cvline{}{Computer Networks (A-), Broadband Mobile Communications (A-)}
%\cvline{}{GPA: 4.0/4.0}

%\section{Skills}
%\cvline{}{Java, C/C++, Python, Matlab, JavaScript, PHP }

%\newpage
\section{Working Experience}
\cvline{September 2019 -- Present}{Research Assistant, Networking and Multimedia System Lab, Department of Computer Science, NTHU}
\cvline{March 2020 -- Present}{Assistant System Administrator, Computer and Communication Center, NTHU}
\\


